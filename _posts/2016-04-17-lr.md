---
layout: post
title: linear regression & logistic regression note
date: 2016-04-17 12:00:00
---
#### **1,linear regression - 线性回归**

线性回归的公式如下所示

$$ y=w^Tx+b $$

广义的线性回归的公式如下所示

$$ y=w^Th(x)+b $$

cost function或者loss function一般为均方误差，目的是使得均方误差最小

$$ j(\theta)=\frac{1}{2}\sum_{i=1}^{m}(h_{0}(x^{(i)})-y^{(i)})^2 $$

w和b的解法为

* 最小二乘法
* 梯度下降

#### **2,logistic regression - 逻辑回归**

$$ y=\frac{1}{1+e^{-(w^Tx + b)}} \tag{2.1} $$

$$ \frac{y}{1-y}\tag{2.2} $$

$$ \ln\frac{y}{1-y}=w^Tx+b\tag{2.3} $$

逻辑回归公式如式2.1所示，式2.2的结果为几率，式2.3对几率取对数，结果是线性回归的公式,
所以逻辑回归的翻译不是很准确，应该是对数几率（logit）

#### **3,正则化项**

* L1正则化：参数绝对值的和，可以让模型稀疏

$$ L(1) = \sum_{i=1}^{m}|x| $$

* L2正则化：参数平方和

$$ L(2) = \sum_{i=1}^{m}|x|^{2} $$

* Ln正则化

$$ L(n) = \sum_{i=1}^{m}|x|^{n} $$

正则化通过限制模型的复杂度，使得复杂的模型可以在有限大小的数据上进行训练，而不会产生严重的过拟合
