<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="/css/main.css">
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          processEscapes: true
        }
      });
    </script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> 
    <title>wpandveil</title>
</head>
<body>
    <main>
        <header class="site-header">
            <h1 class="site-title"><a href="/">wpandveil</a></h1>
        </header>
        <article class="post">
    <h2 class="post-header">linear regression & logistic regression note</h2>
    <p class="post-meta">2016-04-17</p>
    <h4 id="linear-regression---"><strong>1,linear regression - 线性回归</strong></h4>

<p>线性回归的公式如下所示</p>

<script type="math/tex; mode=display">y=w^Tx+b</script>

<p>广义的线性回归的公式如下所示</p>

<script type="math/tex; mode=display">y=w^Th(x)+b</script>

<p>cost function或者loss function一般为均方误差，目的是使得均方误差最小</p>

<script type="math/tex; mode=display">j(\theta)=\frac{1}{2}\sum_{i=1}^{m}(h_{0}(x^{(i)})-y^{(i)})^2</script>

<p>w和b的解法为</p>

<ul>
  <li>最小二乘法</li>
  <li>梯度下降</li>
</ul>

<h4 id="logistic-regression---"><strong>2,logistic regression - 逻辑回归</strong></h4>

<script type="math/tex; mode=display">y=\frac{1}{1+e^{-(w^Tx + b)}} \tag{2.1}</script>

<script type="math/tex; mode=display">\frac{y}{1-y}\tag{2.2}</script>

<script type="math/tex; mode=display">\ln\frac{y}{1-y}=w^Tx+b\tag{2.3}</script>

<p>逻辑回归公式如式2.1所示，式2.2的结果为几率，式2.3对几率取对数，结果是线性回归的公式,
所以逻辑回归的翻译不是很准确，应该是对数几率（logit）</p>

<h4 id="section"><strong>3,正则化项</strong></h4>

<ul>
  <li>L1正则化：参数绝对值的和，可以让模型稀疏</li>
</ul>

<script type="math/tex; mode=display">L(1) = \sum_{i=1}^{m}|x|</script>

<ul>
  <li>L2正则化：参数平方和</li>
</ul>

<script type="math/tex; mode=display">L(2) = \sum_{i=1}^{m}|x|^{2}</script>

<ul>
  <li>Ln正则化</li>
</ul>

<script type="math/tex; mode=display">L(n) = \sum_{i=1}^{m}|x|^{n}</script>

<p>正则化通过限制模型的复杂度，使得复杂的模型可以在有限大小的数据上进行训练，而不会产生严重的过拟合</p>

    
      <div id="disqus_thread"></div>
      <script type="text/javascript">
        var disqus_shortname  = 'httpwwwwpandveilxyz';
        var disqus_identifier = '/2016/04/17/lr';
        (function() {
          var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
          dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
      </script>
    
</article>

    </main>
    
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-41999243-1', 'auto');
        ga('send', 'pageview');
    </script>
    
</body>
</html>
